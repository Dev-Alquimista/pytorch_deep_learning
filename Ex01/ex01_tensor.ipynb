{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex01_tensor.ipynb","provenance":[],"authorship_tag":"ABX9TyOeuW/EtRCOeK7uzsqZCasa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### PyTorch \n","1. PyTorch의 개요 \n","    * PyTorch 는 2017년 초에 공개된 Deep-Learning Framework로 Lua 언어로 개발되었던 Torch를 Facebook에서 Python 버전으로 내놓은 것이다 .\n","    * Torch는 Python의 Numpy Library처럼 과학연산을 위한 Library로 공개되었지만 이후 발전을 거듭하면서 Deep-Learning Framework로 발전 \n","    * PyTorch는 Python 기반의 과학 연산 package로 다음 두 집단을 대상으로 한다. \n","        - Numpy를 대체하면서 GPU를 이용한 연산이 필요한 경우 \n","        - 최대한의 유연성과 속도를 제공하는 Deep-Learning 연구 Platform 이 필요한 경우  \n","2. PyTorch의 특징 및 장점 \n","    * GPU에서 tensor 조작 및 동적 신경망 구축이 가능한 Framework \n","    * GPU(Graphics Processing Unit) \n","        - 연산속도를 빠르게 하는 역할 \n","        - Deep-Learning에서는 기울기를 계산할 때 미분을 쓰는데 GPU를 사용하면 빠른 계산이 가능 \n","        - 내부적으로 CUDA, cuDNN이라는 API를 통해서 GPU를 연산에 적용 가능하다. \n","    * Tensor \n","        - tensor은 PyTorch의 데이터 형태이다. \n","        - tensor안 단일 데이터 형식으로 된 다차원의 행렬이다. \n","        - tensor는 간단한 명령어(변수 뒤에 cuda()를 추가)를 사용해서 GPU로 연산을 수행하게 할 수 있다. \n","    * 동적 신경망 \n","        - 훈련을 반복할 때 마다 변경이 가능한 신경망을 의미한다. "],"metadata":{"id":"P32j9dr3RDDV"}},{"cell_type":"markdown","source":["2. PyTorch의 Architecture \n","    * PyTorch의 Architecture는 크게 세개의 층으로 구분 \n","    * 첫번째 계층 : PyTorch API\n","        - 이 계층에서는 사용자가 이해하기 쉬운 API를 제공하여 Tensor에 대한 처리와 신경망을 구축하고 훈련할 수 있도록 돕는다. \n","        - 이 계층에서는 사용자 인터페이스를 제공하지만 실제 계산을 수행하지 않는다. \n","        - torch \n","            - GPU를 지원하는 tensor package \n","        - torch.autigrabm \n","            - Autograb는 tensorflow, Caffe, CNTK와 같은 다른 Deep-Learning 와 가장 차별되는 package 이다. \n","            - 일반적으로 신경멍에서 사소한 변경이 있다면 신경망 구축을 처음부터 다시 시작해야 한다. 하지만 PyTorch는 자동 미분(auto-differentiation) 을 이용하여 미분 계산을 효율적으로 처리한다.  \n","        - torch.nn\n","            - 신경망 구축 및 훈련 package \n","            \n","        - torch.multiprocessing \n","             - PyTorch에서 사용하는 프로세스 전반에 걸쳐서 tensor의 메모리 공유가 가능하다. 따라서 다른 프로세스에서 동일한 tensor에 대한 접근 및 사용이 가능하다. \n","        - torch.utils  \n","            - 기타 유틸리티를 제공하는 패키지\n","    * 두번째 층 : PyTorch Engine\n","        - Autograd C++ \n","            - 가중치와 편향을 업데이트하는 과정에서 필요한 미분을 자동으로 계산하는 해주는 역할 \n","        - Aten C++\n","            - C++ tensor library 제공  \n","        - JIT C++\n","            - 계산을 최적화하기 위한 JIT(Just In-Time) Compiler \n","    * 세번째 층 : 연산 처리 \n","        - TH C \n","        - TH CUDA \n","        - THNN C \n","        - THCUNN CUDA "],"metadata":{"id":"VYZEhlaKiflH"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"dA6f4hTzRBVC","executionInfo":{"status":"ok","timestamp":1656391062268,"user_tz":-540,"elapsed":3626,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"outputs":[],"source":["import torch "]},{"cell_type":"code","source":["print(torch.tensor([[1, 2], [3, 4]]))\n","print(torch.tensor([[1, 2], [3, 4]], dtype=torch.float64))\n","temp = torch.tensor([[1, 2], [3, 4]])\n","print(temp.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwhDa5ISTwRj","executionInfo":{"status":"ok","timestamp":1656369576343,"user_tz":-540,"elapsed":388,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"a28e8a1b-f8d1-4283-d0d8-e710fb0304fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n","tensor([[1., 2.],\n","        [3., 4.]], dtype=torch.float64)\n","[[1 2]\n"," [3 4]]\n"]}]},{"cell_type":"code","source":["temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n","print(temp[0], temp[1], temp[2])\n","print(temp[2:5])\n","print(temp[4:-1])\n","print(temp[:-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCDxVtyzdfWC","executionInfo":{"status":"ok","timestamp":1656372020135,"user_tz":-540,"elapsed":309,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"39dfe70c-4e31-4537-852f-9f946f0f3472"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.) tensor(2.) tensor(3.)\n","tensor([3., 4., 5.])\n","tensor([5., 6.])\n","tensor([1., 2., 3., 4., 5., 6.])\n"]}]},{"cell_type":"markdown","source":["#### tenosr 연산 및 조작 "],"metadata":{"id":"jxXNN6zqd78U"}},{"cell_type":"code","source":["v = torch.tensor([1, 2, 3])\n","w = torch.tensor([3, 4, 5])\n","print(v - w)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SArqIvYTd4EO","executionInfo":{"status":"ok","timestamp":1656372102226,"user_tz":-540,"elapsed":315,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"f18a081e-661a-4c70-a18e-77fdac707588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-2, -2, -2])\n"]}]},{"cell_type":"markdown","source":["tensor 차원 및 조작 "],"metadata":{"id":"2pcha1bXeSVf"}},{"cell_type":"code","source":["# 2 * 2 matrix \n","temp = torch.tensor([[1, 2], [3, 4]])\n","print(f\"length :{len(temp)}\")\n","print(f\"shape :{temp.shape}\") \n","print(f\"type :{type(temp)}\")\n","\n","# 4 * 1 matrix \n","print(temp.view(4, 1))\n","temp = temp.view(4,1)\n","print(temp.shape)\n","\n","# 1 * 4 matrix \n","temp= temp.view(1, -1)\n","print(temp.shape)\n","\n","# 1 * 1* 4 matrix \n","temp = temp.view(1, 1, 4, 1)\n","print(temp)"],"metadata":{"id":"CFBS2BLbeWsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656391273562,"user_tz":-540,"elapsed":1320,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"006e8181-56cc-4d0f-da2d-6ea332dd576e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["length :2\n","shape :torch.Size([2, 2])\n","type :<class 'torch.Tensor'>\n","tensor([[1],\n","        [2],\n","        [3],\n","        [4]])\n","torch.Size([4, 1])\n","torch.Size([1, 4])\n","tensor([[[[1],\n","          [2],\n","          [3],\n","          [4]]]])\n"]}]}]}