{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex02_FashionCNN.ipynb","provenance":[],"authorship_tag":"ABX9TyNXJysikMEcHMge/C8lYtqS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torchviz\n","!pip intasll pytorch-model-summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdSMu5FN2VNV","executionInfo":{"status":"ok","timestamp":1657670369703,"user_tz":-540,"elapsed":3720,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"022b2917-6265-4aa9-e448-af88f878d1f5"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchviz in /usr/local/lib/python3.7/dist-packages (0.0.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n","ERROR: unknown command \"intasll\" - maybe you meant \"install\"\n"]}]},{"cell_type":"code","execution_count":44,"metadata":{"id":"J7klC5sqq4Ot","executionInfo":{"status":"ok","timestamp":1657670323381,"user_tz":-540,"elapsed":462,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"outputs":[],"source":["import os \n","import cv2 \n","import sys \n","import sklearn \n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","\n","import torch.nn as nn\n","import torch.nn  \n","import torch.nn.functional as F \n","\n","\n","import torchvision \n","import torchvision.transforms as transforms \n","\n","from sklearn.model_selection import train_test_split \n","from torchviz import make_dot\n","from torchinfo import  \n","\n","from torch.autograd import Variable \n","from torch.utils.data import Dataset, DataLoader   "]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"tB2UHbF7t9I8","executionInfo":{"status":"ok","timestamp":1657668192093,"user_tz":-540,"elapsed":309,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_dataset = torchvision.datasets.FashionMNIST(\n","    \"FashionMNIST/\", \n","    download=True, \n","    transform = transforms.Compose([transforms.ToTensor()]))\n","\n","test_dataset = torchvision.datasets.FashionMNIST(\n","    \"FashionMNIST/\", \n","    download=True, \n","    train=False, \n","    transform = transforms.Compose([transforms.ToTensor()]))\n"],"metadata":{"id":"pSyqcSTwuQHs","executionInfo":{"status":"ok","timestamp":1657668378101,"user_tz":-540,"elapsed":538,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size = 100)\n","test_loader = DataLoader(test_dataset, batch_size = 100)\n"],"metadata":{"id":"zZsQF3f7u1N1","executionInfo":{"status":"ok","timestamp":1657668459501,"user_tz":-540,"elapsed":443,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["labels_map = {0 : 'T-Shirt', \n","              1 : 'Trouser', \n","              2 : 'Pullover', \n","              3 : 'Dress', \n","              4 : 'Coat', \n","              5 : 'Sandal', \n","              6 : 'Shirt',\n","              7 : 'Sneaker', \n","              8 : 'Bag', \n","              9 : 'Ankle Boot'}"],"metadata":{"id":"GRUcymaCvWKW","executionInfo":{"status":"ok","timestamp":1657668622080,"user_tz":-540,"elapsed":323,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def show_version():\n","    print(\"=========version=========\")\n","    print(f\"python : {sys.version}\")\n","    print(f\"torch : {torch.__version__}\")\n","    print(f\"numpy : {np.__version__}\")\n","    print(f\"pandas  : {pd.__version__}\")    \n","    print(f\"sklearn :  {sklearn.__version__}\")\n","\n","def show_grid_images():\n","    nrows=5 \n","    ncols=4\n","    fig = plt.figure(figsize=(12, 12))\n","    \n","    for i in range(1, 5*4 +1):\n","        image_xy = np.random.randint(len(train_dataset))\n","        image = train_dataset[image_xy][0][0, :, :]\n","        fig.add_subplot(nrows, ncols, i)\n","        plt.title(labels_map[train_dataset[image_xy][1]])\n","        plt.axis(\"off\")\n","        plt.imshow(image, cmap=\"gray\")\n","    plt.show()"],"metadata":{"id":"rEVZCa3Zv-Lg","executionInfo":{"status":"ok","timestamp":1657668993051,"user_tz":-540,"elapsed":376,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["show_version()\n","show_grid_images()"],"metadata":{"id":"M6L1abMfwbe1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FashionCNN(nn.Module):\n","    def __init__(self):\n","        super(FashionCNN, self).__init__()\n","        # layer1 \n","        # kernel_size 3 * 3 \n","        # channel = depth \n","\n","        self.layer1 = nn.Sequential( \n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1), \n","            nn.BatchNorm2d(32), \n","            nn.ReLU(), \n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","\n","        self.fc1 = nn.Linear(in_features=64 * 6 * 6, out_features=600)\n","        self.drop = nn.Dropout2d(0.25)\n","        self.fc2 = nn.Linear(in_features=600, out_features=120)\n","        self.fc3 = nn.Linear(in_features=120, out_features=10)\n","\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1) \n","        out = self.fc1(out) \n","        out = self.drop(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        return out \n"],"metadata":{"id":"OQUj1C_Zxcth","executionInfo":{"status":"ok","timestamp":1657671005638,"user_tz":-540,"elapsed":317,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.001\n","model = FashionCNN()\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSF7pqy70CYI","executionInfo":{"status":"ok","timestamp":1657671011387,"user_tz":-540,"elapsed":324,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"7bc50115-b701-461d-ab4b-4a9d75aad088"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["FashionCNN(\n","  (layer1): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n","  (drop): Dropout2d(p=0.25, inplace=False)\n","  (fc2): Linear(in_features=600, out_features=120, bias=True)\n","  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["num_epochs = 5 \n","count = 0 \n","# 1 \n","loss_list = [] \n","iteration_list = [] \n","accuracy_list = [] \n","\n","prediction_list = [] \n","labels_list = [] \n","\n","for epoch in range(num_epochs):\n","    # 2 \n","    for images, labels in train_loader: \n","        # 3 \n","        images , labels  = images.to(device), labels.to(device)\n","\n","        \n","        train = Variable(images.view(100, 1, 28, 28))\n","        labels = Variable(labels)\n","\n","        outputs = model(train)\n","        loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        count += 1 \n","\n","        if not (count % 50): \n","            total = 0 \n","            correct = 0 \n","\n","            for images, labels in test_loader: \n","                images, labels = images.to(device), labels.to(device)\n","                labels_list.append(labels)\n","                test = Variable(images.view(100, 1, 28, 28))\n","                outputs = model(test)\n","                predictions = torch.max(outputs, 1)[1].to(device)\n","                prediction_list.append(predictions)\n","\n","                correct += (predictions == labels).sum()\n","                total += len(labels)\n","            \n","            # 5 \n","            accuracy = correct * 100 / total \n","            # 1 \n","            loss_list.append(loss.data)\n","            iteration_list.append(count)\n","            accuracy_list.append(accuracy)\n","\n","        \n","        if not(count % 500):\n","            print(f\"Iteration : {count} \\nLoss : {loss.data} \\nAccuracy : {accuracy}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4mK3fjj17mN","executionInfo":{"status":"ok","timestamp":1657671978028,"user_tz":-540,"elapsed":877218,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"96fd987a-6596-477d-b071-319a4516c726"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Iteration : 500 \n","Loss : 0.4936823546886444 \n","Accuracy : 87.9800033569336\n","Iteration : 1000 \n","Loss : 0.3157854676246643 \n","Accuracy : 89.54000091552734\n","Iteration : 1500 \n","Loss : 0.3250182271003723 \n","Accuracy : 88.54000091552734\n","Iteration : 2000 \n","Loss : 0.22408969700336456 \n","Accuracy : 89.62999725341797\n","Iteration : 2500 \n","Loss : 0.144230455160141 \n","Accuracy : 89.83000183105469\n","Iteration : 3000 \n","Loss : 0.18140695989131927 \n","Accuracy : 90.05000305175781\n"]}]}]}