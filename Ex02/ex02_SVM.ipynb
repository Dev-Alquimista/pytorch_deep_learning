{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex02_SVM.ipynb","provenance":[],"authorship_tag":"ABX9TyNlAZNK0m8vdh2QOZ0AJFwa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### SVM(Support Vector Machine)\n","* SVM은 분류를 위한 기준선을 정의하는 모델 \n","* 분류되지 않은 새로운 데이터가 나타나면 결정 경계(기준선)를 기준으로 경계의 어느 쪽에 속하는지를 분류하는 모델이다.\n","* SVM에서는 결정경계를 이해하는 것이 중요하다. \n","* 결정경계는 데이터를 분류하기 위한 기준선이다.\n","* 결정경계는 데이터가 분류된 클래스에서 최대한 멀리 떨어져있을 때 성능이 가장 좋다.\n","* SVM을 이해하기 위해서는 margin이라는 개념을 이해할 필요가 있는데, margin은 결정 경계가 support vector(결정 경계와 가까이에 있는 데이터)사이의 거리를 의미하고, 결국 이 데이터들이 경계를 정의하는 결정적인 역할을 한다.\n","* 최적의 결정 경계는 margin을 최대로 해야 한다.  \n","* SVM운 데이터들을 올바르게 분리하면서 margin크기를 최대호 해야 하는데 결국 이상치(outlier)를 잘 다루는 것이 중요하다. \n","    - soft margin : 어느 정도의 이상치들이 margin에 포함되는 것을 허용\n","    - hard margin : 이상치를 margin에 포함되는 것을 허용하지 않음 \n"," "],"metadata":{"id":"MGKw9N0u6j8I"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"a2vX1CaZ6hmv","executionInfo":{"status":"ok","timestamp":1656414735330,"user_tz":-540,"elapsed":2804,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import seaborn \n","import sklearn \n","import os \n","import tensorflow as tf\n","from google.colab import drive  "]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split \n","from sklearn.metrics import accuracy_score \n","from sklearn.preprocessing import StandardScaler \n","from sklearn import datasets\n","from sklearn import svm"],"metadata":{"id":"VZDykDmC8qP6","executionInfo":{"status":"ok","timestamp":1656415925389,"user_tz":-540,"elapsed":7,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","# log \n","# default 0 : 모든 log 표시\n","# INFO : 1 \n","# WARNING : 2\n","# ERROR : 3 "],"metadata":{"id":"oQ5VqPwDAx6m","executionInfo":{"status":"ok","timestamp":1656414836279,"user_tz":-540,"elapsed":327,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["drive.mount(\"/content/drive/\")\n","FILE_PATH = \"/content/drive/MyDrive/dataset/pytorch/iris.data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_3BZuFV89pe","executionInfo":{"status":"ok","timestamp":1656414282293,"user_tz":-540,"elapsed":2686,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"d3cb3117-6b99-4d33-be21-5227d38a9afc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n","dataset = pd.read_csv(FILE_PATH, names=names)"],"metadata":{"id":"lYU2GV4L-xto","executionInfo":{"status":"ok","timestamp":1656414341849,"user_tz":-540,"elapsed":338,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def get_show_shape_array(np_array):\n","    for i in range(len(np_array)):\n","        print(f\"shape {np_array[i].shape}\")\n","\n","def get_show_shape_dict(dict):\n","    for key, value in dict.items():\n","        print(f\"{key}, {value.shape}\")"],"metadata":{"id":"l665k1Ri_-L2","executionInfo":{"status":"ok","timestamp":1656414705680,"user_tz":-540,"elapsed":325,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["dataset.head(n=10)\n","X = dataset.iloc[:, :-1].values\n","Y = dataset.iloc[:, 4].values\n","print(f\"X shape {X.shape}\")\n","print(f\"X type {type(X)}\")\n","print(f\"X lengtth {len(X)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8rKthxk_SOt","executionInfo":{"status":"ok","timestamp":1656414466797,"user_tz":-540,"elapsed":358,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"e2076621-23cf-45aa-e21a-b13fdd74be06"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["X shape (150, 4)\n","X type <class 'numpy.ndarray'>\n","X lengtth 150\n"]}]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state =2022)\n","dict_data =  {\"x_train\": x_train, \"x_test\":x_test, \"y_train\":y_train, \"y_test\":y_test }\n","get_show_shape_dict(dict_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1-s6xZ0_xjW","executionInfo":{"status":"ok","timestamp":1656414716070,"user_tz":-540,"elapsed":326,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"4cbac98a-f98c-4870-874f-4d93ded2101a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train, (120, 4)\n","x_test, (30, 4)\n","y_train, (120,)\n","y_test, (30,)\n"]}]},{"cell_type":"code","source":["iris = datasets.load_iris()\n","x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.6, random_state=42)"],"metadata":{"id":"fRgIJqCMBSah","executionInfo":{"status":"ok","timestamp":1656415070909,"user_tz":-540,"elapsed":324,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["#### Support Vector Machine kernel  \n","* SVM은 선형 분류와 비선형 분류를 지원한다. \n","* 비선형 문제를 해결하는 가장 기본적인 방법은 저차원의 데이터를 고차원으로 보내는 것이다. 하지만 이것은 많은 수학적 계산이 필요하기 때문에 성능에 문제를 준다. \n","* 이러한 문제를 해결하기 위해서 나온 것이 바로 **kernel trick**이다. \n","* 선형 모델을 위한 kernel에는 linear kernel이 있고 비선형을 위한 kernel에는 \n","gaussian kernel(RBF:Radial Basis Function), polynomial kernel 이 있다. \n","    - linear kernel \n","$$K(a, b) = a^T* b $$\n","$$(a, b) : \\text{input vector}$$\n","    - polynomoal kernel \n","        - 실제로는 특성을 추가하지는 않지만 다항식 특성을 많이 추가한 것과 같은 결과를 얻을 수 있는 방법 \n","        - 엄청난 수의 특성 조합이 생기는 것과 같은 효과를 얻기 때문에 고차원으로 데이터 매핑이 가능 \n","\n","        $$K(a, b) = (\\gamma a^T*b)^d$$ \n","        $$\\gamma\\text{ : gamma  d : dimension}$$\n","        $$ \\gamma\\text{ , d  : hyper parameter} $$\n","    - gaussian kernel \n","        - polynomoal kernel의 확장 \n","        - 입력 vector를 차원이 무한한 고차원으로 매핑하는 것 모든 차수의 다항식을 고려한다.\n","        $$K(a, b) = exp(-\\gamma||a-b||^2)$$ \n","        $$ \\gamma\\text{: hyper parameter} $$\n","\n","* C 값이 클수록 hard margin 이고 작을수록 soft margin에 해당한다. \n","* gamma 는 결정 경계를 얼마나 유연하게 가져갈지를 결정한다. \n","* gamma값이 높으면 training에 많이 의존을 하게 되기 때문에 결정 경계가 곡선형태를 뛰며 overfitting 를 초래할 수 있다. \n"],"metadata":{"id":"oTZom420Fqrx"}},{"cell_type":"code","source":["svm = svm.SVC(kernel=\"linear\", C=1.0, gamma=0.5)\n","svm.fit(x_train, y_train)\n","predictions = svm.predict(x_test)\n","score = accuracy_score(y_test, predictions)\n","print(f\"accuracy {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FofzHbuCC0s","executionInfo":{"status":"ok","timestamp":1656415928590,"user_tz":-540,"elapsed":340,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"6bb50f94-e57b-4485-b359-2fe6516018fd"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy 0.9888888888888889\n"]}]}]}